## Decidability

Of course, just because the law of excluded middle isn't constructively true
*in general* doesn't mean it's *never true.* For example, I can show that any
natural number is, or is not, 0:

```agda
open import Data.Nat using (ℕ; zero; suc)
open import Relation.Binary.PropositionalEquality
open import Relation.Nullary using (¬_)
open import Data.Sum

is-zero?⅋ : (n : ℕ) → (n ≡ 0) ⊎ (¬ (n ≡ 0))
is-zero?⅋ zero    = inj₁ refl
is-zero?⅋ (suc n) = inj₂ λ ()   -- ! 1
```

The first case here is easy enough to understand, but the second might require a
little explanation. At [1](Ann), we have pattern matched on the argument and
know that it is a `suc`, not a `zero`. Thus, we are required to show `suc n ≡
zero`, which is clearly not the case, because in Agda, data constructors are
always apart. In order to show this is false, we must provide a function `(suc n
≡ zero) → ⊥`. Simply pattern matching on the argument is enough for Agda to
figure out we're clearly talking nonsense, and it replaces our lambda pattern
with `()` showing there is no such proof.

So, what differentiates our ability to determine whether `n ≡ 0`, but not some
arbitrary proposition `P`? We call the difference *decidability* --- a property
`P` is decidable if and only if it's possible to determine whether `P` or `¬ P`
holds. Rather than overload poor `_⊎_` to satisfy this property for us, we will
instead define a new type:

```agda
module Hypothetical where
  data Dec (P : Set) : Set where
    yes :  P → Dec P
    no : ¬ P → Dec P
```

Rather than use the clumsy names `inj₁` and `inj₂`, we instead say `yes` if the
proposition holds, and `no` if it doesn't. We can rewrite `is-zero?` in terms of
our new machinery:

```agda
  is-zero? : (n : ℕ) → Dec (n ≡ 0)
  is-zero? zero    = yes refl
  is-zero? (suc n) = no λ ()
```

Besides the simplified type and the new constructor names, nothing has changed
here. But what does decidability really mean? It means there is a *decision
procedure* (an algorithm) which we can run to tell us the answer. For example,
there's a decision procedure that will tell us if two natural numbers are equal
--- namely, keep making them smaller and see if they both get to `zero` at the
time:

```agda
  _≟_ : (x y : ℕ) → Dec (x ≡ y)
  zero  ≟ zero  = yes refl
  zero  ≟ suc y = no λ ()
  suc x ≟ zero  = no λ ()
```

This definition of `_≟_` is not quite complete; we still need to show the
`suc`/`suc` case is decidable. But the trick, as always, is to recurse,
using the decidability of if the smaller numbers are equal, and if so, lifting
the proof to one of the successed numbers.

```agda
  suc x ≟ suc y
    with x ≟ y
  ... | yes x=y = yes (cong suc x=y)  -- ! 1
  ... | no  x≠y = no λ sx=sy → x≠y (suc-injective sx=sy)  -- ! 2
    where
      open import Data.Nat.Properties using (suc-injective)
```

In the `yes` case at [1](Ann), we are required to turn a proof of `x ≡ y` into a
proof that `suc x ≡ suc y`, which is an obvious application of `cong suc`.
However, due to the way we've constructed propositional refutation, at
[2](Ann) we need to go the other direction --- turning a proof of `suc x ≡ suc
y` into a proof that `x ≡ y` (that is, so we can refute that fact via `x≠y`.)
There is clearly some sort of "backwardness" going on here in the `no` case. We
will explore this further in a moment.

Maybe you are wondering why decidability is an important property to have.
Perhaps its most salient feature is that it is helpful in connecting the messy
outside world to the crisp, inner logic of a dependently typed programming
language. Data that comes from the outside world is subject to the whims of
users, and is unlikely to be well-typed, let alone *dependently-typed.*

The notion of decidability generalizes to any sort of decision procedure which
results in a proof one way or another. One common form of decidability you're
likely familiar with is the *trichotomy* of `_<_`; that is, the fact that for
any `x y : ℕ`, exactly one of the following propositions holds: `x < y`, `x ≡
y`, or `x > y`. We can define trichotomy:

```agda
open import Data.Nat using (_<_; _>_; _≤_; z≤n; s≤s)

data <-Trichotomy (x y : ℕ) : Set where
  tri< : x < y → <-Trichotomy x y
  tri≈ : x ≡ y → <-Trichotomy x y
  tri> : x > y → <-Trichotomy x y
```

and then witness the trichotomy of `_<_` via `<-cmp`:

```agda
<-cmp : (x y : ℕ) → <-Trichotomy x y
<-cmp zero zero = tri≈ refl
<-cmp zero (suc y) = tri< (s≤s z≤n)
<-cmp (suc x) zero = tri> (s≤s z≤n)
<-cmp (suc x) (suc y) with <-cmp x y
... | tri< x<y = tri< (s≤s x<y)
... | tri≈ x≈y = tri≈ (cong suc x≈y)
... | tri> x>y = tri> (s≤s x>y)
```

The `<-cmp` is a decision procedure fully capable of not only determining which
of two numbers is bigger, but also of *proving* why it's so. We will use this
trichotomy immediately in our next example of decidability.

Let's consider the case of a *binary search tree* (BST) of natural numbers. A
BST has the property that every value in the left sub-tree of a branch is
smaller than the node at the branch, and likewise, every value on the right is
larger. We can encode such a thing in Agda by tracking the smallest and largest
elements in the tree as indices on the type.

Under this framing, a BST is either empty with arbitrary bounds (albeit with the
constraint that the lower bound is smaller than the higher bound):

```agda
open Data.Nat using (_≤_; z≤n; s≤s)

data BST : ℕ → ℕ → Set where
  ⊘ : {lo hi : ℕ} → ⦃ lo ≤ hi ⦄ → BST lo hi
```

or alternatively, that we have a branch that satisfies the BST invariant stating
sub-trees are well-organized with respect to the root node:

```agda
  branch' : {lo hi : ℕ}
         → (n : ℕ)
         → (l : BST lo n)
         → (r : BST n hi)
         → BST lo hi
```

When we visualize binary search trees, we prefer to put the left sub-tree on the
left of the root node, but `branch'` doesn't allow us to do this, since `l`
depends on `n`. We can use a little syntactic sugar in the form of a pattern to
alleviate this problem:


```agda
pattern _◁_▷_ l n r = branch' n l r
```

Furthermore, it's tedious to need to write `⊘ ◁ n ▷ ⊘` whenever we want a leaf,
so we can add a pattern for that too.

```agda
pattern leaf n = ⊘ ◁ n ▷ ⊘
```

The goal is now that we'd like to insert a value guaranteed to be in bounds
into an existing `BST`. This latter constraint simplifies the problem, meaning
we don't need to determine new bounds for the `BST`, which would be an exercise
in patience. We begin with the type of `insert`:

```agda
open import Data.Nat.Properties using (≤-trans; n≤1+n)

insert
    : {lo hi : ℕ} → (n : ℕ)
    → ⦃ lo ≤ n ⦄ → ⦃ n≤h : n ≤ hi ⦄
    → BST lo hi
    → BST lo hi
```

If we are trying to insert into the empty tree, we can just leave a `leaf`
behind:

```agda
insert n ⊘ = leaf n
```

However, the branch case is much more interesting. We will need to recursively
insert our value into the sub-trees, but doing so requires us to have a proof
that our value is inside the bounds of the sub-tree. All we know, however, is
that the value is contained by the bounds of the entire tree. It's clear that
for an arbitrary value, this is going to require a runtime check, which is to
say, a decidable test of how `n` relates to `i`. The attentive reader will
notice that this is a perfect use-case for `<-cmp`.

By inspecting how `n` relates to `i`, we can refine our proofs of how `n` sits
in the bounds of the sub-trees.

```agda
insert n (l ◁ i ▷ r)
  with <-cmp n i
... | tri≈ n=i = l ◁ i ▷ r
... | tri< n<i =
  insert n ⦃ n≤h = ≤-trans (n≤1+n n) n<i ⦄ l ◁ i ▷ r
... | tri> i<n =
  l ◁ i ▷ insert n ⦃ (≤-trans (n≤1+n i) i<n) ⦄ r
```

You might be puzzled by the instance arguments used by `⊘` and `insert`; these
exist so that we can ask Agda to automatically solve the necessary bounds
proofs. By giving instances for both constructors of the irrelevant `_≤_`, Agda
will happily construct `x ≤ y` proofs whenever `x` and `y` are known statically:

```agda
private instance
  z≤ : {n : ℕ} → 0 ≤ n
  z≤ = z≤n

  s≤ : {a b : ℕ} → ⦃ a ≤ b ⦄ → suc a ≤ suc b
  s≤ ⦃ a≤b ⦄ = s≤s a≤b
```

We can now test our handiwork. By constructing an empty `BST` with explicit
bounds:

```agda
b : BST 0 100
b = ⊘
```

we are able to `insert` several values into it, and inspect the resulting value
in all of its glory:

```agda
_ : insert 3
      (insert 5
        (insert 10
          (insert 12
            (insert 5
              (insert 42 b)))))
    ≡ (leaf 3 ◁ 5 ▷ (leaf 10 ◁ 12 ▷ ⊘)) ◁ 42 ▷ ⊘
_ = refl
```

Inspecting the results, you can see that, read left-to-right, all numbers are in
ascending order. Furthermore, the duplicated `5` element only made it into the
resultant tree once.

Decidability (and its related forms, like trichotomy) is an important feature of
*computation,* and is the primary means of differentiating mathematics from
computation. Math requires no decidability, computation is useless without it.

